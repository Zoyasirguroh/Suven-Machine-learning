{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering on Numeric Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Even though numeric data can be directly fed into Machine Learning models, you would still need to engineer features that are relevant to the scenario, problem, and domain before building a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##--Import necessary dependencies and settings\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import scipy.stats as spstats\n",
    "\n",
    "mpl.style.reload_library()\n",
    "mpl.style.use('classic')\n",
    "mpl.rcParams['figure.facecolor'] = (1, 1, 1, 0)\n",
    "mpl.rcParams['figure.figsize'] = [6.0, 4.0]\n",
    "mpl.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##----Lets engineer on \"Raw data from the Pokémon dataset\"\n",
    "poke_df = pd.read_csv('datasets_module_4/Pokemon.csv')\n",
    "print(poke_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- showing values for just 3 important columns\n",
    "print(poke_df[['HP', 'Attack', 'Defense']].head())\n",
    "\n",
    "# These indicate each Pokémon’s HP (Hit Points), Attack, and Defense stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--we can also compute some basic statistical measures on these fields\n",
    "print(poke_df[['HP', 'Attack', 'Defense']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--working now on a different dataset\n",
    "popsong_df = pd.read_csv('datasets_module_4/song_views.csv')\n",
    "print(popsong_df.head(10))\n",
    "\n",
    "# sample of data from the million-song dataset, which depicts \n",
    "# counts or frequencies of songs that have been heard by various users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For example if I want to know if a person is interested or has listened to a particular song, I do not need to know the total number of times he/she has listened to the same song. I am more concerned about the various songs he/she has listened to. In this case, a binary feature is preferred as opposed to a count based feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--We can binarize our listen_count field from our earlier dataset\n",
    "watched = np.array(popsong_df['listen_count'])\n",
    "watched[watched >= 1] = 1\n",
    "popsong_df['watched'] = watched\n",
    "print(popsong_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rounding\n",
    "Often when dealing with numeric attributes like proportions or percentages, we may not need values with a high amount of precision. Hence it makes sense to round off these high precision percentages into numeric integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_popularity = pd.read_csv('datasets_module_4/item_popularity.csv')\n",
    "\n",
    "# rounding off percentages\n",
    "items_popularity['popularity_scale_10'] = np.array(np.round((items_popularity['pop_percent'] * 10)), dtype='int')\n",
    "items_popularity['popularity_scale_100'] = np.array(np.round((items_popularity['pop_percent'] * 100)), dtype='int')\n",
    "\n",
    "print(items_popularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binning"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Often when working with numeric data, you might come across features or attributes which depict raw measures such as values or frequencies.\n",
    "\n",
    "Suppose we are talking about song or video view counts. In some cases, the view counts will be abnormally large and in some cases very small. Directly using these features in modeling might cause issues.\n",
    "\n",
    "Solution : There are various ways to engineer features from these raw values so\n",
    "we can solve these issues. These methods include transformations, scaling and binning/quantization. \n",
    "\n",
    "We will code and understand about binning which is also known as quantization. The operation of binning is used for transforming continuous numeric values into discrete ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Binning\n",
    "# -- dataset for binning\n",
    "fcc_survey_df = pd.read_csv('datasets_module_4/fcc_2016_coder_survey_subset.csv')\n",
    "print(fcc_survey_df[['ID.x', 'EmploymentField', 'Age', 'Income']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##---Fixed-width binning\n",
    "##---Developer age distribution\n",
    "fig, ax = plt.subplots()\n",
    "fcc_survey_df['Age'].hist(color='#A9C5D3')  # default no. of bins = 10\n",
    "ax.set_title('Developer Age Histogram', fontsize=12)\n",
    "ax.set_xlabel('Age', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Binning based on rounding\n",
    "# \n",
    "# ``` \n",
    "# Age Range: Bin\n",
    "# ---------------\n",
    "#  0 -  9  : 0\n",
    "# 10 - 19  : 1\n",
    "# 20 - 29  : 2\n",
    "# 30 - 39  : 3\n",
    "# 40 - 49  : 4\n",
    "# 50 - 59  : 5\n",
    "# 60 - 69  : 6\n",
    "#   ... and so on\n",
    "# ```\n",
    "\n",
    "fcc_survey_df['Age_bin_round'] = np.array(np.floor(np.array(fcc_survey_df['Age']) / 10.))\n",
    "fcc_survey_df[['ID.x', 'Age', 'Age_bin_round']].iloc[1071:1076]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Binning based on custom ranges\n",
    "# \n",
    "# ``` \n",
    "# Age Range : Bin\n",
    "# ---------------\n",
    "#  0 -  15  : 1\n",
    "# 16 -  30  : 2\n",
    "# 31 -  45  : 3\n",
    "# 46 -  60  : 4\n",
    "# 61 -  75  : 5\n",
    "# 75 - 100  : 6\n",
    "# ```\n",
    "\n",
    "bin_ranges = [0, 15, 30, 45, 60, 75, 100]\n",
    "bin_names = [1, 2, 3, 4, 5, 6]\n",
    "fcc_survey_df['Age_bin_custom_range'] = pd.cut(np.array(fcc_survey_df['Age']), bins=bin_ranges)\n",
    "fcc_survey_df['Age_bin_custom_label'] = pd.cut(np.array(fcc_survey_df['Age']), bins=bin_ranges, labels=bin_names)\n",
    "fcc_survey_df[['ID.x', 'Age', 'Age_bin_round', 'Age_bin_custom_range', 'Age_bin_custom_label']].iloc[1071:1076]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Adaptive Binning\n",
    "----------------\n",
    "So far, we have decided the bin width and ranges in fixed-width binning. However, this technique can lead to irregular bins that are not uniform based on the number of data points or values which fall in each bin. \n",
    "\n",
    "Some of the bins might be densely populated and some of them might be sparsely populated or even be empty!\n",
    "\n",
    "Adaptive binning is a safer and better approach where we use the data distribution itself to decide what should be the appropriate bins.\n",
    "\n",
    "Quantile based binning is a good strategy to use for adaptive binning.\n",
    "\n",
    "q-Quantiles help in partitioning a numeric attribute into q equal partitions. Popular examples of quantiles include the 2-Quantile known as the median which divides the data distribution into two equal bins, 4-Quantiles known as the quartiles, which divide the data into four equal bins and 10-Quantiles also known as the deciles which create 10 equal width bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantile based Binning\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fcc_survey_df['Income'].hist(bins=30, color='#A9C5D3')\n",
    "ax.set_title('Developer Income Histogram', fontsize=12)\n",
    "ax.set_xlabel('Developer Income', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# see carefully : there is a right skew with lesser\n",
    "# developers earning more money and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s take a 4-Quantile or a quartile based adaptive binning scheme.\n",
    "\n",
    "quantile_list = [0, .25, .5, .75, 1.]\n",
    "quantiles = fcc_survey_df['Income'].quantile(quantile_list)\n",
    "print(quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 4 quantile histogram \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fcc_survey_df['Income'].hist(bins=30, color='#A9C5D3')\n",
    "\n",
    "for quantile in quantiles:\n",
    "    qvl = plt.axvline(quantile, color='r')\n",
    "\n",
    "ax.legend([qvl], ['Quantiles'], fontsize=10)\n",
    "\n",
    "ax.set_title('Developer Income Histogram with Quantiles', fontsize=12)\n",
    "ax.set_xlabel('Developer Income', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Transformations\n",
    "Let’s look at a different strategy of feature engineering on numerical data by using statistical or mathematical transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The log transform belongs to the power transform family of functions. \n",
    "# This function can be defined as y = logb(x) \n",
    "fcc_survey_df['Income_log'] = np.log((1+ fcc_survey_df['Income']))\n",
    "fcc_survey_df[['ID.x', 'Age', 'Income', 'Income_log']].iloc[4:9]\n",
    "\n",
    "# we are doing +1 to the 'Income' to avoid taking log of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s now plot the data distribution of this log-transformed feature\n",
    "income_log_mean = np.round(np.mean(fcc_survey_df['Income_log']), 2)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fcc_survey_df['Income_log'].hist(bins=30, color='#A9C5D3')\n",
    "plt.axvline(income_log_mean, color='r')\n",
    "ax.set_title('Developer Income Histogram after Log Transform', fontsize=12)\n",
    "ax.set_xlabel('Developer Income (log scale)', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "ax.text(11.5, 450, r'$\\mu$='+str(income_log_mean), fontsize=10)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Thus we can clearly see that the original developer income distribution that was right skewed in previous Figure is more Gaussian or normal-like in above Figure after applying the log transform."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
